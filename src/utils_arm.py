# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hqs076Up2eOso7BemYGo0mL8QeIvXeFZ
"""

import numpy as np
import torch
import os
import pandas as pd
import itertools as it
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
from torchvision import transforms
import matplotlib.pyplot as plt

def moving_window(x, length, step=1, stride=5):
    streams = it.tee(x, length)
    return zip(*[it.islice(stream, i, None, step*stride) for stream, i in zip(streams, it.count(step=step))])

def windower(file_path, i, input_frames, predicted_frames, my_stride, segment_name = 'All'):

    my_stride = 3*my_stride
    window_len = 3*input_frames
    predicted_window_len = 3*predicted_frames

    path2files = os.path.join(file_path, f's{i}_fn')

    segment_names = {'Head' : [0, 1, 2, 3],
                    'Body' : [4, 5, 6, 7, 8, 9, 10],
                    'LArm' : [11, 12, 13, 14, 15, 16, 17],
                    'RArm' : [18, 19, 20, 21, 22, 23, 24],
                    'Pelvis' : [25, 26, 27, 28],
                    'LLeg' : [29, 30, 31, 32, 33, 34],
                    'RLeg' : [35, 36, 37, 38, 39, 40],
                    'All' : list(range(41)),
                    'Arm' : [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24],
                    'Leg' : [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40],
                    'Body_Pelvic' : [4, 5, 6, 7, 8, 9, 10, 25, 26, 27, 28]
    }



    # segment_start, segment_end = segment_names[segment_name][0], segment_names[segment_name][-1]
    segment_ind = segment_names[segment_name]

    data_ls = []


    for item in os.listdir(path2files):

        path2item = os.path.join(path2files, item)
        df = pd.read_csv(path2item, header=None).to_numpy()
        simple_ftrs = df[:7, -1]

        x_=list(moving_window(df[:df.shape[0]-predicted_window_len, segment_ind], window_len, step=1, stride=my_stride))
        x_=np.asarray(x_)

        y_=list(moving_window(df[window_len:, segment_ind], predicted_window_len, step=1, stride=my_stride))
        y_=np.asarray(y_)

        xs = []
        for x in x_:
            whole_x = np.zeros((input_frames, len(segment_names[segment_name])*3+7))
            whole_x[:, :len(segment_names[segment_name])*3] = x.reshape(input_frames, -1)
            whole_x[:, len(segment_names[segment_name])*3:] = simple_ftrs
            xs.append(whole_x)

        xs = np.asarray(xs)
        my_data = list(zip(xs, y_.reshape(y_.shape[0],predicted_frames, -1)))

        data_ls.extend(my_data)

    return data_ls, y_

def read_test(file_path, segment_name = 'All'):

  segment_names = {'Head' : [0, 1, 2, 3],
                    'Body' : [4, 5, 6, 7, 8, 9, 10],
                    'LArm' : [11, 12, 13, 14, 15, 16, 17],
                    'RArm' : [18, 19, 20, 21, 22, 23, 24],
                    'Pelvis' : [25, 26, 27, 28],
                    'LLeg' : [29, 30, 31, 32, 33, 34],
                    'RLeg' : [35, 36, 37, 38, 39, 40],
                    'All' : list(range(41)),
                    'Arm' : [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24],
                    'Leg' : [29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40],
                    'Body_Pelvic' : [4, 5, 6, 7, 8, 9, 10, 25, 26, 27, 28]
    }

  # segment_start, segment_end = segment_names[segment_name][0], segment_names[segment_name][-1]
  segment_ind = segment_names[segment_name]
  segment_len = len(segment_names[segment_name])
  my_ls = []
  file_ls = []
  
  for item in os.listdir(file_path):
    print(item)
    path2item = os.path.join(file_path, item)
    df = pd.read_csv(path2item, header=None).to_numpy()
    simple_ftrs = df[:7, -1]
    my_data = np.zeros((101, len(segment_names[segment_name])*3+7))
    my_data[:, :len(segment_names[segment_name])*3] = df[:, segment_ind].reshape(101, -1)
    my_data[:, len(segment_names[segment_name])*3:] = simple_ftrs
    my_ls.append(my_data)
    file_ls.append(path2item)
    

  return my_ls, segment_len*3, file_ls

def L_Pred(data, ind, model, transform, num_input_f, num_pred_f, seg_len, device):
  with torch.no_grad():
    validation_target = torch.from_numpy(data[ind]).float().to(device)
    validation_predictions = torch.zeros(101, seg_len+7).to(device)
    validation_predictions[:num_input_f, :] = validation_target[:num_input_f, :]

    # validation_predictions[:, -7:] = validation_target[:, -7:]
    sub_info = validation_target[:num_pred_f, -7:]
    last_x = validation_target[:num_input_f, :]
    i = 0

    while i<(101-num_input_f):
      input_ = last_x
      p = model(input_.reshape(1, num_input_f, -1).float())
      p = torch.cat((p.reshape(num_pred_f, -1), sub_info), dim=1)
      validation_predictions[num_input_f+i, :] = p

      last_x = torch.cat((last_x[num_pred_f:], p))
      i = i + 1


    validation_target = transform(validation_target[:, 0:seg_len].reshape(1, 101, seg_len))
    validation_predictions = transform(validation_predictions[:, 0:seg_len].reshape(1, 101, seg_len))
  return validation_target, validation_predictions

def O_Pred(data, ind, model, transform, num_input_f, num_pred_f, seg_len, device):
  validation_target = torch.from_numpy(data[ind]).float().to(device)
  validation_predictions = validation_target[:num_input_f, :]
  sub_info = validation_target[:num_pred_f, -7:]
  last_x = validation_target[:num_input_f, :]
  i = 1

  while validation_predictions.shape[0] < validation_target.shape[0]:
    input_ = last_x
    p = model(input_.reshape(1, num_input_f, -1).float())
    p = torch.cat((p.reshape(num_pred_f, -1), sub_info), dim=1)
    validation_predictions = torch.cat((validation_predictions, p))


    last_x = validation_target[i:num_input_f+i, :]
    i = i + 1

  validation_target = transform(validation_target[:, 0:seg_len].reshape(1, 101, seg_len))
  validation_predictions = transform(validation_predictions[:, 0:seg_len].reshape(1, 101, seg_len))

  return validation_target, validation_predictions

class Denormalizer(object):
  def __init__(self, data_mean, data_std, num_predicted, device):
    self.data_mean = data_mean
    self.data_std = data_std
    self.num_predicted = num_predicted
    Means = pd.concat(num_predicted*[data_mean], axis=0)
    Means.reset_index(inplace=True, drop=True)
    self.Means = torch.tensor(Means.values).reshape(num_predicted, -1).to(device).float()
    Stds = pd.concat(num_predicted*[data_std], axis=0)
    Stds.reset_index(inplace=True, drop=True)
    self.Stds = torch.tensor(Stds.values).reshape(num_predicted, -1).to(device).float()


  def __call__(self, normal_data):
    # normal_data = normal_data.reshape(self.num_predicted*3, -1)
    return (normal_data * self.Stds + self.Means)

class MyDataset(Dataset):
  def __init__(self, data_list, target_transform=None):
    self.data = data_list
    self.target_transform = target_transform

  def __len__(self):
    return len(self.data)

  def __getitem__(self, idx):

    input = torch.from_numpy(self.data[idx][0])

    if self.target_transform is not None:
      label = self.target_transform(torch.from_numpy(self.data[idx][1]))
    else:
      label = torch.from_numpy(self.data[idx][1])

    return input, label

class Lstm(nn.Module):
    def __init__(self, n_inputs, n_hidden, n_rnnlayers, n_outputs, n_pr_frames, device):
        super(Lstm, self).__init__()

        self.D = n_inputs
        self.M = n_hidden
        self.L = n_rnnlayers
        self.K = n_outputs
        self.n_pr_frames = n_pr_frames
        self.device = device

        self.lstm = nn.LSTM(
        input_size=self.D,
        hidden_size=self.M,
        num_layers=self.L,
        batch_first=True,
        bidirectional=True
        )

        self.fc = nn.Linear(2*self.M*n_pr_frames, self.K*self.n_pr_frames)

        # xavier weight initialization for rnn
        for name, param in self.lstm.named_parameters():
            if 'weight' in name:
                nn.init.xavier_uniform_(param)

    def forward(self, X):
        b_z, l, f = X.shape
        h0 = torch.zeros(2*self.L, X.size(0), self.M).to(self.device)
        c0 = torch.zeros(2*self.L, X.size(0), self.M).to(self.device)
        out, _ = self.lstm(X, (h0, c0))
        # print(out.shape)
        out = self.fc(out[:, -1, :])
        out = out.reshape(b_z, self.n_pr_frames, -1)

        return out

def count_parameters(model):
   return sum(p.numel() for p in model.parameters() if p.requires_grad)

def BGD(model,
        criterion,
        optimizer,
        train_loader,
        test_loader,
        epochs,
        scheduler,
        transform,
        device):

  train_losses = np.zeros(epochs)
  test_losses = np.zeros(epochs)
  DTWs = np.zeros(epochs)
  best_val_loss = float('inf')
  best_DTW = float('inf')

  for it in range(epochs):
    model.train()
    train_loss_list = []
    for inputs, targets in train_loader:
      inputs, targets = inputs.to(device).float(), targets.to(device).float()
      optimizer.zero_grad()
      outputs = model(inputs)
      loss = criterion(transform(outputs), transform(targets))

      loss.backward()
      optimizer.step()
      # scheduler.step(loss)
      train_loss_list.append(loss.item())

    train_losses[it] = sum(train_loss_list)/len(train_loss_list)

    model.eval()
    test_loss_list = []
    with torch.no_grad():
      for inputs, targets in test_loader:
        inputs, targets = inputs.to(device).float(), targets.to(device).float()
        test_outputs = model(inputs)
        test_loss = criterion(transform(test_outputs), transform(targets))
        test_loss_list.append(test_loss.item())

      test_losses[it] = sum(test_loss_list)/len(test_loss_list)

    DTWs[it] = DTW_compute(model)


    if (it + 1) % 5 == 0:
        print(f'Epoch {it+1}/{epochs}, Train Loss: {train_losses[it]:.5f}, Test Loss: {test_losses[it]:.5f}, DTW: {DTWs[it]:.5f}')
    if scheduler is not None:
      scheduler.step(test_losses[it])

    if test_losses[it] < best_val_loss:
      best_val_loss = test_losses[it]
      torch.save(model.state_dict(), "best_val_model_params.pt")

    if DTWs[it] < best_DTW:
      best_DTW = DTWs[it]
      torch.save(model.state_dict(), "best_DTW_model_params.pt")



  return train_losses, test_losses, DTWs

def train_loop(model,
        criterion,
        optimizer,
        train_loader,
        test_loader,
        epochs,
        scheduler,
        transform,
        device,
        length_calc):

  model.train()
  train_loss_list = []
  marker_loss_list = []

  for inputs, targets in train_loader:
    inputs, targets = inputs.to(device).float(), targets.to(device).float()
    optimizer.zero_grad()
    outputs = model(inputs)

    len_true = torch.zeros(targets.shape[0], 4)
    len_pred = torch.zeros(targets.shape[0], 4)

    len_true[:, 0] = length_calc(inputs, 'RSHO', 'RELB', 'Right Arm')
    len_true[:, 1] = length_calc(inputs, 'RELB', 'RWRA', 'Right ForeArm')
    len_true[:, 2] = length_calc(inputs, 'LSHO', 'LELB', 'Left Arm')
    len_true[:, 3] = length_calc(inputs, 'LELB', 'LWRA', 'Left ForeArm')

    
    len_pred[:, 0] = length_calc(outputs, 'RSHO', 'RELB', 'Right Arm')
    len_pred[:, 1] = length_calc(outputs, 'RELB', 'RWRA', 'Right ForeArm')
    len_pred[:, 2] = length_calc(outputs, 'LSHO', 'LELB', 'Left Arm')
    len_pred[:, 3] = length_calc(outputs, 'LELB', 'LWRA', 'Left ForeArm')

    len_true = len_true.reshape(-1, 1, 4)
    len_pred = len_pred.reshape(-1, 1, 4)

    loss, loss_marker = criterion(outputs, targets, len_true, len_pred, transform)   

    # loss_marker = criterion(transform(outputs), transform(targets))
    # loss_len = criterion(len_true, len_pred)

    # loss = 10 * loss_len + loss_marker
    
    
    loss.backward()
    optimizer.step()
    # scheduler.step(loss)
    train_loss_list.append(loss.item())
    marker_loss_list.append(loss_marker.item())

  return sum(train_loss_list)/len(train_loss_list), sum(marker_loss_list)/len(marker_loss_list)


def test_loop(model,
        criterion,
        optimizer,
        train_loader,
        test_loader,
        epochs,
        scheduler,
        transform,
        device,
        length_calc):

  model.eval()
  test_loss_list = []
  marker_loss_list = []

  with torch.no_grad():
    for inputs, targets in test_loader:
      inputs, targets = inputs.to(device).float(), targets.to(device).float()
      test_outputs = model(inputs)

      len_true = torch.zeros(targets.shape[0], 4)
      len_pred = torch.zeros(targets.shape[0], 4)

      len_true[:, 0] = length_calc(inputs, 'RSHO', 'RELB', 'Right Arm')
      len_true[:, 1] = length_calc(inputs, 'RELB', 'RWRA', 'Right ForeArm')
      len_true[:, 2] = length_calc(inputs, 'LSHO', 'LELB', 'Left Arm')
      len_true[:, 3] = length_calc(inputs, 'LELB', 'LWRA', 'Left ForeArm')

      
      len_pred[:, 0] = length_calc(test_outputs, 'RSHO', 'RELB', 'Right Arm')
      len_pred[:, 1] = length_calc(test_outputs, 'RELB', 'RWRA', 'Right ForeArm')
      len_pred[:, 2] = length_calc(test_outputs, 'LSHO', 'LELB', 'Left Arm')
      len_pred[:, 3] = length_calc(test_outputs, 'LELB', 'LWRA', 'Left ForeArm')

      len_true = len_true.reshape(-1, 1, 4)
      len_pred = len_pred.reshape(-1, 1, 4)

      loss, loss_marker = criterion(test_outputs, targets, len_true, len_pred, transform) 
    #   loss_len = criterion(len_true, len_pred)

    #   test_loss = 10 * loss_len + loss_marker

      test_loss_list.append(loss.item())
      marker_loss_list.append(loss_marker.item())

  return sum(test_loss_list)/len(test_loss_list), sum(marker_loss_list)/len(marker_loss_list)

